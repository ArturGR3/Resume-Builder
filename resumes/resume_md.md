
## Contact Details
### Name: Artur Grygorian
### Target Positions: Data Science & Analytics, Machine Learning Engineer, AI Engineer, Data Engineer, Technical Product Manager, Head Of Analytics.

### Potential Location: Berlin, Germany (1st preference, work visa); Atlanta, GA, USA (3rd preference, citizen); Remote from Germany (2nd preference, work visa); Remote from USA (4th preference, citizen);
### Email: arturgrygorian3@gmail.com  
### [LinkedIn](https://www.linkedin.com/in/arturgrygorian/)  
### [Medium](https://medium.com/@arturgrygorian3)  
### [GitHub](https://github.com/ArturG3)

## SUMMARY
With a decade of hands-on experience spanning supply chain and eCommerce. I bring a wealth of knowledge in advanced data analytics, modeling, and team leadership. I have had significant individual impact as well as built high performing teams from scratch. In my new role I am looking to solve complex analytical problems using modern machine learning and AI tools. 

## PROFESSIONAL EXPERIENCE

### Sr. Manager Analytics (or Head of Delivery Analytics) (Global Fulfilment Speed)
**Wayfair**, Berlin, Germany | Aug 2022 - Aug 2024

- Head of Global Analytics Team (EU, UK, USA) responsible for strategy of tech implementation to improve delivery promise accuracy.
- Designed Target setting framework that translated company wide initiatives relevant to delivery promise into actionable targets for the team. Helping stakeholders to understand the impact of their initiatives on the delivery promise to decide priorities.
- Boosted speed badging (fast delivery promise saturation) by 1500 bps by improving accuracy of delivery speed model and resolving tech debt. Which resulted in additional ~$5M in annual GRS via higher conversion.
- Together with ML engineers designed and implemented A/B testing, measuring the conversion impact of faster delivery promise to justify strategic initiatives.
- Designed causal inference framework to estimate the impact of delivery speed on conversion, controlling for other factors that might affect conversion. This framework was used to guide the investment in faster delivery network and to estimate the ROI of the initiative.
- Built a high performing team of 5+ data scientists and analytics engineers focusing on delivering high quality analytics and AI solutions.

### Analytics Manager (or Head of EU Delivery Analytics) (EU Fulfilment Speed)
**Wayfair**, Berlin, Germany | Jun 2021 - Aug 2022

- As a Head of EU analytics engineering team, responsible for delivery promise accuracy efforts, with a specific focus on supplier lead time and carrier speed. Provided analytics support to Operations teams via building data pipelines and dashboards that enabled them to make data-driven decisions.
- Developed a machine learning based model to estimate the delivery time for the EU network that improved speed by 1.3 days, resulting in a substantial increase in conversion that brought an additional ~â‚¬10M in annual GRS
- Established key performance indicators (KPIs) and designed supportive dashboards to evaluate the health of the delivery network. Led Weekly Business Reviews (WBRs) and Monthly Business Reviews (MBRs), bringing insights to executive leadership
- Led strategy promotion strategy for delivery promise speed for high volume events like Black Friday, Christmas and Wayday. Involved stakeholders from across the company to ensure alignment and buy-in for the initiatives.

### Analytics Manager (or Head of Delivery Analytics) (Delivery Speed)
**The Home Depot**, Atlanta, GA, USA | Sep 2019 - Apr 2021

- Created an Machine Learning based model that improved delivery promise by 0.7 days without impact on delivery reliability, resulting in >$100M in annual GRS via higher conversion
- Supported operations teams with data insights, uncovered problematic areas in the network through exploratory analytics, and collaborated on solutions. Created Multiple data pipelines using SQL Server and Google BigQuery to connect carrier, warehouse and customer data to build a comprehensive view of the delivery network.
- Established and led data science team of 3 people from inception, hiring, mentoring, and guiding the team to become one of the most impactful teams in the organization, which lead to multiple awards and recognitions at the company.

### Senior Data Analyst (Inbound Network Optimization)
**The Home Depot**, Atlanta, GA, USA | Aug 2017 - Sep 2019

- Developed and implemented a truckload rounding model, which used simulation and optimization techniques to determine the optimal number of truckloads to round up to based on the forecasted demand, resulting in annual savings of ~$5M in transportation costs
- Implemented enhancements to the truckload planning model improving data pipeline and adding new features during migration from SQL Server to Google BigQuery, which allowed to reduce the time of the planning process from 2 days to 15 minutes
- Moved several key reports from Excel to Tableau, that made discovery of insights easier and more interactive for the stakeholders
- Recognized for outstanding performance, promoted to Senior Data Analyst in 10 months, was nominated with Homer Award for the most impactful project.

## EDUCATION

- **Master's in Statistics**  
  Georgia Southern University  
  Best Graduate Assistant Award, GPA 4.0/4.0
  Statesboro, GA, USA  
  2015 - 2017

- **Master's in Economics**  
  Kyiv School of Economics  
  Won KPMG Case Competition Ukraine, Finalist of EY Case Competition Ukraine
  Kyiv, Ukraine  
  2012 - 2014

- **Master's in Mathematics**  
  Odesa National University  
  Odesa, Ukraine  
  2007 - 2013

## TECHNOLOGY STACK

### Programming Languages and Data Analysis
- Python (pandas, numpy, scipy, scikit-learn, xgboost, lightgbm, catboost, optuna, sklearn-genai, langchain, Instructor)
- R (tidyverse, ggplot2, dplyr, tidymodels, caret, xgboost, lightgbm, catboost, optuna)
- SQL (BigQuery, SQL Server)

### Data Storage and Retrieval
- Vector Databases: LanceDB, FAISS, ElasticSearch

### Data Visualization
- Tools: Tableau, Data Studio, Looker, matplotlib, seaborn, plotly, streamlit, gradio

### Machine Learning and AI
- Frameworks: PyTorch, TensorFlow, Scikit-learn, AutoGluon, LightAutoML
- Algorithms: xgboost, lightgbm, catboost
- MLOps: MLflow
- GenAI: Instructor, RAG (Retrieval Augmented Generation, with text, semantic and hybrid search), LangChain
- AI Services: OpenAI, Anthropic, Gemini, Ollama, Groq

### Cloud Platforms
- AWS: S3, EC2, Kinesis, Lambda
- GCP: BigQuery, Vertex AI

### Development Tools
- Version Control: GitHub
- Containerization: Docker
- Build Automation: Makefile
- IDEs and Productivity Tools: VSCode, Copilot, Cursor

## Certifications and Trainings: 

### [LLM Bootcamp (DataTalks.Club)](https://certificate.datatalks.club/llm-zoomcamp/2024/55db812d19a5b355790d127cb88ca72afdc49df5.pdf) - Oct 2024:

Key Technologies and Concepts:
- Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG)
- OpenAI API and open-source models (HuggingFace Hub, Ollama)
- Search technologies: Elasticsearch for text and vector search
- Vector databases and embeddings
- UI development with Streamlit
- Evaluation techniques: Offline evaluation, cosine similarity, LLM-as-a-Judge metrics
- Monitoring: Chat history tracking, user feedback, Grafana dashboards
- Data ingestion and orchestration with Mage
- Advanced RAG techniques: Hybrid search, document reranking
- Integration with LangChain for improved RAG pipelines
- Setting up LLM environments (GPU and CPU)
- Implementing RAG systems with various search methods
- Evaluating and monitoring LLM-based systems
- Orchestrating LLM workflows and data ingestion
- Applying best practices for RAG pipeline optimization

### [MLOps Bootcamp (DataTalks.Club)](https://certificate.datatalks.club/mlops-zoomcamp/2024/55db812d19a5b355790d127cb88ca72afdc49df5.pdf) - Sep 2024:

Key Technologies and Concepts:
- Introduction to MLOps concepts and maturity models
- Experiment tracking and model management using MLflow
- Workflow orchestration 
- Model deployment strategies: web services (Flask), streaming (AWS Kinesis, Lambda), and batch processing
- Monitoring ML services using Prometheus and Grafana
- Best practices: testing, code quality (linting, formatting)

### [Applied Tiny Machine Learning (TinyML) for Scale (HarvardX)](https://courses.edx.org/certificates/06d1d51303de4beb87ee52fad25642d6) - March 2023

Key Technologies and Concepts:
- Machine Learning: Data preprocessing, model training, optimization for resource-constrained devices
- TensorFlow Lite: Deployment of tiny ML models on low-power devices
- MLOps for TinyML: Automation of ML lifecycle, scalable deployments
- TinyML Applications: Case studies, project design, real-world implementation
- Advanced Techniques: Neural architecture search, federated learning
- Technologies: TensorFlow Lite for Microcontrollers, MLOps tools for TinyML
- Skills Acquired: Developing, deploying, and scaling TinyML applications across domains

### [Generative AI with Large Language Models (Coursera, DeepLearning.AI)](https://coursera.org/share/9459a80d6710c6beebe8355a73b52368) - October 2023

Key Technologies and Concepts:
- Generative AI fundamentals: Lifecycle, transformer architecture, LLMs
- Model optimization: Pre-training, fine-tuning, PEFT, empirical scaling laws
- Advanced techniques: RLHF, chain-of-thought prompting, information retrieval
- Practical application: Hands-on experience with state-of-the-art LLM training, tuning, and deployment

### [Exam 461: Querying Microsoft SQL Server 2012/2014 (Microsoft)](https://www.credly.com/badges/10cdbd7b-affb-4112-9eb9-45a9c2f9e725/linked_in_profile) - May 2018

Key Technologies and Concepts:
- Database Objects: Tables, constraints, views, stored procedures, functions, triggers
- Data Manipulation: Complex SELECT queries, subqueries, joins, T-SQL functions
- Data Modification: INSERT, UPDATE, DELETE, transactions, merge statements
- Query Optimization: Performance analysis, indexing, execution plans
- T-SQL Programming: Stored procedures, user-defined functions, triggers
- Advanced Concepts: Transaction management, error handling, dynamic SQL, XML and spatial data

**Project**: [End to End ML Deployment Using AutoGluon and OpenFE](https://github.com/ArturGR3/MLOps-project) - Jun 2024

Purpose: Create a template for rapid MVP deployment of machine learning models with automated feature engineering and MLOps best practices.

Key Technologies and Concepts:
- AutoML: AutoGluon for automated model selection and training
- Feature Engineering: OpenFE for automated feature generation
- Cloud Infrastructure: Google Cloud VM, AWS EC2, S3
- Experiment Tracking: MLflow
- Containerization: Docker
- Orchestration: Makefile
- Monitoring: Grafana
- Testing: Unit and integration tests

### [LLM Bootcamp (DataTalks.Club)](https://certificate.datatalks.club/llm-zoomcamp/2024/55db812d19a5b355790d127cb88ca72afdc49df5.pdf) - Oct 2024:

Key Technologies and Concepts:
- Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG)
- OpenAI API and open-source models (HuggingFace Hub, Ollama)
- Search technologies: Elasticsearch for text and vector search
- Vector databases and embeddings
- UI development with Streamlit
- Evaluation techniques: Offline evaluation, cosine similarity, LLM-as-a-Judge metrics
- Monitoring: Chat history tracking, user feedback, Grafana dashboards
- Data ingestion and orchestration with Mage
- Advanced RAG techniques: Hybrid search, document reranking
- Integration with LangChain for improved RAG pipelines
- Setting up LLM environments (GPU and CPU)
- Implementing RAG systems with various search methods
- Evaluating and monitoring LLM-based systems
- Orchestrating LLM workflows and data ingestion
- Applying best practices for RAG pipeline optimization

**Project**: [RAG for Recipe Recommendation System](https://github.com/ArturGR3/food_search_RAG) - Sep 2024

Purpose: Implement a food recipe recommendation system using RAG (Retrieval-Augmented Generation) to help users find relevant recipes based on their queries.

Key Technologies and Concepts:
- RAG (Retrieval-Augmented Generation) with FAISS, LanceDB(FTS, Vector and Hybrid search)
- LLM-based relevance scoring, filtering and query preprocessing
- Gradio for user interface with feedback collection
- Docker containerization for reproducibility
- SQLite and comprehensive logging for monitoring of user feedback and click-stream data
- Asyncio for concurrent API calls for generating synthetic data for preliminary retrieval evaluation
- LLM Factory for managing different LLM APIs (Groq, OpenAI, Anthropic)
- Instructor Library for structuring LLM output
- Automated data collection, preprocessing and synthetic data generation
- Advanced recipe retrieval and ranking system

## Projects: 
### [YouTube Transcript Analyzer](https://github.com/ArturGR3/Youtube-transcript-Q-A) - Oct 2024

Purpose: Analyze YouTube video transcripts using LLMs to provide a summary of main topics, timestamps, and enable Q&A based on video content.

Key Technologies and Concepts:
- YouTube Transcript API for fetching video transcripts
- LLM integration for content analysis and Q&A
- Instructor library for structured output generation
- CSV file handling for transcript storage and retrieval
- Streaming structural output with Partial class from Instructor
- Token estimation and API cost calculation
- User-friendly interface with prompts for video analysis

### [LLM Kaggle Winning Solution](https://github.com/ArturGR3/LLM-kaggle-competition) - Sep 2024

Purpose: Develop a winning solution for the LLMZoomCamp Kaggle competition focused on solving math problems using Large Language Models (LLMs).

Key Technologies and Concepts:
- Claude-3.5 Sonnet LLM with zero-shot chain of thought reasoning
- LLM Python code generation and execution with safety controls
- Structured outputs using Instructor library
- Multithreading for concurrent problem-solving
- Robust error handling and retry mechanisms with timeouts
